{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 05:08:32,460 - MainThread - INFO - Registered CONST v1.0.0\n",
      "2025-11-24 05:08:32,460 - MainThread - INFO - Registered ADD v1.0.0\n",
      "2025-11-24 05:08:32,461 - MainThread - INFO - Registered MULTIPLY v1.0.0\n",
      "2025-11-24 05:08:32,463 - MainThread - INFO - ============================================================\n",
      "2025-11-24 05:08:32,463 - MainThread - INFO - Starting execution engine\n",
      "2025-11-24 05:08:32,463 - MainThread - INFO - Mode: thread, Max workers: 4\n",
      "2025-11-24 05:08:32,463 - MainThread - INFO - ============================================================\n",
      "2025-11-24 05:08:32,464 - MainThread - INFO - Topological sort complete: 3 levels, 7 nodes\n",
      "2025-11-24 05:08:32,464 - MainThread - INFO - Execution plan (3 levels):\n",
      "2025-11-24 05:08:32,464 - MainThread - INFO -   Level 0: ['ConstA', 'ConstB', 'ConstC', 'ConstD']\n",
      "2025-11-24 05:08:32,465 - MainThread - INFO -   Level 1: ['Add1', 'Multiply1']\n",
      "2025-11-24 05:08:32,465 - MainThread - INFO -   Level 2: ['Add2']\n",
      "2025-11-24 05:08:32,465 - MainThread - INFO - \n",
      "============================================================\n",
      "2025-11-24 05:08:32,465 - MainThread - INFO - Executing Level 0\n",
      "2025-11-24 05:08:32,465 - MainThread - INFO - ============================================================\n",
      "2025-11-24 05:08:32,465 - MainThread - INFO - Executing level with 4 node(s) in parallel\n",
      "2025-11-24 05:08:32,466 - ThreadPoolExecutor-78_0 - INFO - Executing ConstA\n",
      "2025-11-24 05:08:32,466 - ThreadPoolExecutor-78_1 - INFO - Executing ConstB\n",
      "2025-11-24 05:08:32,466 - ThreadPoolExecutor-78_2 - INFO - Executing ConstC\n",
      "2025-11-24 05:08:32,466 - ThreadPoolExecutor-78_3 - INFO - Executing ConstD\n",
      "2025-11-24 05:08:32,468 - ThreadPoolExecutor-78_3 - INFO - Completed ConstD: {'output1': 10}\n",
      "2025-11-24 05:08:32,467 - ThreadPoolExecutor-78_1 - INFO - Completed ConstB: {'output1': 4}\n",
      "2025-11-24 05:08:32,468 - ThreadPoolExecutor-78_2 - INFO - Completed ConstC: {'output1': 3}\n",
      "2025-11-24 05:08:32,467 - ThreadPoolExecutor-78_0 - INFO - Completed ConstA: {'output1': 10}\n",
      "2025-11-24 05:08:32,470 - MainThread - INFO - Level completed in 0.004s (4/4 nodes)\n",
      "2025-11-24 05:08:32,470 - MainThread - INFO - \n",
      "============================================================\n",
      "2025-11-24 05:08:32,470 - MainThread - INFO - Executing Level 1\n",
      "2025-11-24 05:08:32,470 - MainThread - INFO - ============================================================\n",
      "2025-11-24 05:08:32,470 - MainThread - INFO - Executing level with 2 node(s) in parallel\n",
      "2025-11-24 05:08:32,470 - ThreadPoolExecutor-79_0 - INFO - Executing Add1\n",
      "2025-11-24 05:08:32,471 - ThreadPoolExecutor-79_1 - INFO - Executing Multiply1\n",
      "2025-11-24 05:08:32,526 - ThreadPoolExecutor-79_0 - INFO - Completed Add1: {'output1': 14}\n",
      "2025-11-24 05:08:32,556 - ThreadPoolExecutor-79_1 - INFO - Completed Multiply1: {'output1': 30}\n",
      "2025-11-24 05:08:32,557 - MainThread - INFO - Level completed in 0.087s (2/2 nodes)\n",
      "2025-11-24 05:08:32,557 - MainThread - INFO - \n",
      "============================================================\n",
      "2025-11-24 05:08:32,557 - MainThread - INFO - Executing Level 2\n",
      "2025-11-24 05:08:32,558 - MainThread - INFO - ============================================================\n",
      "2025-11-24 05:08:32,558 - MainThread - INFO - Executing level with 1 node(s) in parallel\n",
      "2025-11-24 05:08:32,558 - ThreadPoolExecutor-80_0 - INFO - Executing Add2\n",
      "2025-11-24 05:08:32,654 - ThreadPoolExecutor-80_0 - INFO - Completed Add2: {'output1': 44}\n",
      "2025-11-24 05:08:32,654 - MainThread - INFO - Level completed in 0.096s (1/1 nodes)\n",
      "2025-11-24 05:08:32,655 - MainThread - INFO - \n",
      "============================================================\n",
      "2025-11-24 05:08:32,655 - MainThread - INFO - Execution completed in 0.192s\n",
      "2025-11-24 05:08:32,655 - MainThread - INFO - ============================================================\n",
      "2025-11-24 05:08:32,656 - MainThread - INFO - Graph exported to execution_graph.json\n",
      "2025-11-24 05:08:32,777 - MainThread - INFO - Execution profile saved to execution_profile.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXECUTION STATISTICS\n",
      "============================================================\n",
      "Total time: 0.192s\n",
      "Levels: 3\n",
      "\n",
      "Node Statistics:\n",
      "  ConstA: 1 exec, 3.52ms avg\n",
      "  ConstB: 1 exec, 2.79ms avg\n",
      "  ConstC: 1 exec, 2.65ms avg\n",
      "  ConstD: 1 exec, 2.04ms avg\n",
      "  Add1: 1 exec, 55.89ms avg\n",
      "  Multiply1: 1 exec, 85.99ms avg\n",
      "  Add2: 1 exec, 96.02ms avg\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "Add1 result: 14 (10 + 4)\n",
      "Multiply1 result: 30 (3 * 10)\n",
      "Add2 result: 44 (14 + 30)\n",
      "\n",
      "Graph exported to execution_graph.json\n",
      "Execution profile chart saved to execution_profile.png\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any, List, Set, Optional, Callable\n",
    "from collections import deque\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Configuration and Logging\n",
    "# -------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(threadName)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ExecutionMode(Enum):\n",
    "    \"\"\"Execution mode for the engine.\"\"\"\n",
    "\n",
    "    SEQUENTIAL = \"sequential\"\n",
    "    THREAD = \"thread\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExecutionTrace:\n",
    "    \"\"\"Trace data for a single node execution.\"\"\"\n",
    "\n",
    "    node_name: str\n",
    "    node_type: str\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    duration: float\n",
    "    level: int\n",
    "    thread_id: str\n",
    "    success: bool = True\n",
    "    error: Optional[str] = None\n",
    "\n",
    "    @property\n",
    "    def relative_start(self) -> float:\n",
    "        \"\"\"Start time relative to execution start.\"\"\"\n",
    "        return self.start_time\n",
    "\n",
    "    @property\n",
    "    def relative_end(self) -> float:\n",
    "        \"\"\"End time relative to execution start.\"\"\"\n",
    "        return self.end_time\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NodeMetrics:\n",
    "    \"\"\"Metrics for node execution.\"\"\"\n",
    "\n",
    "    execution_count: int = 0\n",
    "    total_execution_time: float = 0.0\n",
    "    last_execution_time: float = 0.0\n",
    "    error_count: int = 0\n",
    "\n",
    "    def record_execution(self, duration: float):\n",
    "        self.execution_count += 1\n",
    "        self.total_execution_time += duration\n",
    "        self.last_execution_time = duration\n",
    "\n",
    "    def record_error(self):\n",
    "        self.error_count += 1\n",
    "\n",
    "    @property\n",
    "    def avg_execution_time(self) -> float:\n",
    "        if self.execution_count == 0:\n",
    "            return 0.0\n",
    "        return self.total_execution_time / self.execution_count\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NodeDefinition: stateless compute template\n",
    "# -------------------------------------------------------------------\n",
    "class NodeDefinition:\n",
    "    \"\"\"A node definition describes pure logic. No state, no wiring.\n",
    "\n",
    "    For production scalability, NodeDefinitions should be:\n",
    "    - Stateless and pure (no side effects)\n",
    "    - Serializable (for distributed execution)\n",
    "    - Idempotent (safe to retry)\n",
    "    \"\"\"\n",
    "\n",
    "    type_name = \"BASE\"\n",
    "    num_inputs = 0\n",
    "    num_outputs = 0\n",
    "\n",
    "    # Execution hints for optimization\n",
    "    is_expensive = False  # CPU-intensive operations\n",
    "    is_io_bound = False  # I/O operations\n",
    "    estimated_duration_ms = 100  # For scheduling\n",
    "\n",
    "    def compute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Override in subclasses to implement logic.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def validate_inputs(self, inputs: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Validate inputs before execution.\"\"\"\n",
    "        return len(inputs) == self.num_inputs\n",
    "\n",
    "    def serialize(self) -> bytes:\n",
    "        \"\"\"Serialize for distributed execution.\"\"\"\n",
    "        return pickle.dumps(self)\n",
    "\n",
    "    @classmethod\n",
    "    def deserialize(cls, data: bytes) -> \"NodeDefinition\":\n",
    "        \"\"\"Deserialize from bytes.\"\"\"\n",
    "        return pickle.loads(data)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Example NodeDefinitions\n",
    "# -------------------------------------------------------------------\n",
    "class ConstDefinition(NodeDefinition):\n",
    "    type_name = \"CONST\"\n",
    "    num_inputs = 0\n",
    "    num_outputs = 1\n",
    "\n",
    "    def compute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Const nodes do not compute—they're set directly in NodeInstance.\n",
    "        return {}\n",
    "\n",
    "\n",
    "class AddDefinition(NodeDefinition):\n",
    "    type_name = \"ADD\"\n",
    "    num_inputs = 2\n",
    "    num_outputs = 1\n",
    "    estimated_duration_ms = 10\n",
    "\n",
    "    def compute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        time.sleep(random.randrange(0, 10) * 0.01)\n",
    "        return {\"output1\": inputs[\"input1\"] + inputs[\"input2\"]}\n",
    "\n",
    "\n",
    "class MultiplyDefinition(NodeDefinition):\n",
    "    type_name = \"MULTIPLY\"\n",
    "    num_inputs = 2\n",
    "    num_outputs = 1\n",
    "    is_expensive = True\n",
    "    estimated_duration_ms = 50\n",
    "\n",
    "    def compute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Simulate expensive computation\n",
    "        time.sleep(random.randrange(0, 10) * 0.01)\n",
    "        return {\"output1\": inputs[\"input1\"] * inputs[\"input2\"]}\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NodeInstance: runtime wiring + state\n",
    "# -------------------------------------------------------------------\n",
    "class NodeInstance:\n",
    "    \"\"\"Runtime instance with wiring, state, and execution metadata.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, name: str, definition: NodeDefinition, node_id: Optional[str] = None\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.node_id = node_id or name  # Unique identifier\n",
    "        self.definition = definition\n",
    "\n",
    "        # inputN → (source_node, source_output_name)\n",
    "        self.inputs: Dict[str, Any] = {}\n",
    "\n",
    "        # outputN → computed values\n",
    "        self.outputs: Dict[str, Any] = {}\n",
    "\n",
    "        # reverse dependency graph (children needing this output)\n",
    "        self.children: List[\"NodeInstance\"] = []\n",
    "\n",
    "        # parent nodes (dependencies)\n",
    "        self.parents: Set[NodeInstance] = set()\n",
    "\n",
    "        # flag for incremental execution\n",
    "        self.is_dirty = True\n",
    "\n",
    "        # lock for thread-safe output updates\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "        # Execution metrics\n",
    "        self.metrics = NodeMetrics()\n",
    "\n",
    "        # Error handling\n",
    "        self.last_error: Optional[Exception] = None\n",
    "        self.retry_count = 0\n",
    "        self.max_retries = 3\n",
    "\n",
    "    def input_name(self, index: int) -> str:\n",
    "        return f\"input{index}\"\n",
    "\n",
    "    def output_name(self, index: int) -> str:\n",
    "        return f\"output{index}\"\n",
    "\n",
    "    def set_input(\n",
    "        self, input_index: int, src_node: \"NodeInstance\", src_output_index: int\n",
    "    ):\n",
    "        input_key = self.input_name(input_index)\n",
    "        output_key = src_node.output_name(src_output_index)\n",
    "        self.inputs[input_key] = (src_node, output_key)\n",
    "\n",
    "        # Build dependency graph\n",
    "        src_node.children.append(self)\n",
    "        self.parents.add(src_node)\n",
    "\n",
    "    def resolve_inputs(self) -> Dict[str, Any]:\n",
    "        \"\"\"Resolve inputs with validation.\"\"\"\n",
    "        resolved = {}\n",
    "        for input_name, (src_node, src_output_name) in self.inputs.items():\n",
    "            if src_output_name not in src_node.outputs:\n",
    "                raise ValueError(\n",
    "                    f\"Output {src_output_name} not available from {src_node.name}\"\n",
    "                )\n",
    "            resolved[input_name] = src_node.outputs[src_output_name]\n",
    "        return resolved\n",
    "\n",
    "    def to_json(self) -> Dict[str, Any]:\n",
    "        \"\"\"Serialize node state to JSON (for persistence/debugging).\"\"\"\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"node_id\": self.node_id,\n",
    "            \"type\": self.definition.type_name,\n",
    "            \"outputs\": self.outputs,\n",
    "            \"is_dirty\": self.is_dirty,\n",
    "            \"metrics\": {\n",
    "                \"execution_count\": self.metrics.execution_count,\n",
    "                \"avg_execution_time\": self.metrics.avg_execution_time,\n",
    "                \"error_count\": self.metrics.error_count,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<NodeInstance {self.name}>\"\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.node_id)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, NodeInstance) and self.node_id == other.node_id\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# NodeRegistry with versioning and plugin support\n",
    "# -------------------------------------------------------------------\n",
    "class NodeRegistry:\n",
    "    \"\"\"Registry for node definitions with versioning support.\"\"\"\n",
    "\n",
    "    _registry: Dict[str, Dict[str, NodeDefinition]] = (\n",
    "        {}\n",
    "    )  # type -> version -> definition\n",
    "    _latest_versions: Dict[str, str] = {}  # type -> latest version\n",
    "\n",
    "    @classmethod\n",
    "    def register(cls, definition: NodeDefinition, version: str = \"1.0.0\"):\n",
    "        \"\"\"Register a node definition with version.\"\"\"\n",
    "        type_name = definition.type_name\n",
    "\n",
    "        if type_name not in cls._registry:\n",
    "            cls._registry[type_name] = {}\n",
    "            cls._latest_versions[type_name] = version\n",
    "\n",
    "        cls._registry[type_name][version] = definition\n",
    "\n",
    "        # Update latest version (simple string comparison)\n",
    "        if version > cls._latest_versions[type_name]:\n",
    "            cls._latest_versions[type_name] = version\n",
    "\n",
    "        logger.info(f\"Registered {type_name} v{version}\")\n",
    "\n",
    "    @classmethod\n",
    "    def create_definition(\n",
    "        cls, type_name: str, version: Optional[str] = None\n",
    "    ) -> NodeDefinition:\n",
    "        \"\"\"Create a node definition, optionally specifying version.\"\"\"\n",
    "        if type_name not in cls._registry:\n",
    "            raise ValueError(f\"Unknown node type: {type_name}\")\n",
    "\n",
    "        version = version or cls._latest_versions[type_name]\n",
    "\n",
    "        if version not in cls._registry[type_name]:\n",
    "            raise ValueError(f\"Version {version} not found for {type_name}\")\n",
    "\n",
    "        return cls._registry[type_name][version]\n",
    "\n",
    "    @classmethod\n",
    "    def list_types(cls) -> List[str]:\n",
    "        \"\"\"List all registered node types.\"\"\"\n",
    "        return list(cls._registry.keys())\n",
    "\n",
    "\n",
    "# Register definitions\n",
    "NodeRegistry.register(ConstDefinition(), \"1.0.0\")\n",
    "NodeRegistry.register(AddDefinition(), \"1.0.0\")\n",
    "NodeRegistry.register(MultiplyDefinition(), \"1.0.0\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Execution Engine with Production Features\n",
    "# -------------------------------------------------------------------\n",
    "class ExecutionEngine:\n",
    "    \"\"\"Production-ready execution engine with advanced features.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes: List[NodeInstance],\n",
    "        max_workers: int = None,\n",
    "        mode: ExecutionMode = ExecutionMode.THREAD,\n",
    "        enable_checkpointing: bool = False,\n",
    "        checkpoint_callback: Optional[Callable] = None,\n",
    "        enable_profiling: bool = True,\n",
    "    ):\n",
    "        self.nodes = nodes\n",
    "        self.max_workers = max_workers or multiprocessing.cpu_count()\n",
    "        self.mode = mode\n",
    "        self.execution_order: List[List[NodeInstance]] = []\n",
    "        self.enable_checkpointing = enable_checkpointing\n",
    "        self.checkpoint_callback = checkpoint_callback\n",
    "        self.enable_profiling = enable_profiling\n",
    "\n",
    "        # Build node lookup for fast access\n",
    "        self.node_lookup = {node.node_id: node for node in nodes}\n",
    "\n",
    "        # Execution statistics\n",
    "        self.total_execution_time = 0.0\n",
    "        self.level_execution_times: List[float] = []\n",
    "        self.execution_start_time = 0.0\n",
    "\n",
    "        # Profiling data\n",
    "        self.execution_traces: List[ExecutionTrace] = []\n",
    "        self.traces_lock = threading.Lock()\n",
    "\n",
    "    def topological_sort(self) -> List[List[NodeInstance]]:\n",
    "        \"\"\"\n",
    "        Perform topological sort and group nodes by execution level.\n",
    "        Nodes at the same level can be executed in parallel.\n",
    "\n",
    "        Returns: List of levels, where each level is a list of nodes\n",
    "                 that can execute in parallel.\n",
    "        \"\"\"\n",
    "        # Calculate in-degree for each node\n",
    "        in_degree = {node: len(node.parents) for node in self.nodes}\n",
    "\n",
    "        # Find all nodes with no dependencies (in-degree = 0)\n",
    "        queue = deque([node for node in self.nodes if in_degree[node] == 0])\n",
    "\n",
    "        levels = []\n",
    "        processed = 0\n",
    "\n",
    "        while queue:\n",
    "            # All nodes in current queue can execute in parallel\n",
    "            current_level = list(queue)\n",
    "            levels.append(current_level)\n",
    "            queue.clear()\n",
    "            processed += len(current_level)\n",
    "\n",
    "            # Process all nodes in current level\n",
    "            for node in current_level:\n",
    "                # Reduce in-degree of children\n",
    "                for child in node.children:\n",
    "                    in_degree[child] -= 1\n",
    "                    # If all dependencies satisfied, add to next level\n",
    "                    if in_degree[child] == 0:\n",
    "                        queue.append(child)\n",
    "\n",
    "        # Check for cycles\n",
    "        if processed < len(self.nodes):\n",
    "            unprocessed = [n.name for n in self.nodes if in_degree[n] > 0]\n",
    "            raise ValueError(\n",
    "                f\"Cycle detected in node graph. Unprocessed: {unprocessed}\"\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f\"Topological sort complete: {len(levels)} levels, {processed} nodes\"\n",
    "        )\n",
    "        return levels\n",
    "\n",
    "    def mark_dirty(self, node: NodeInstance):\n",
    "        \"\"\"Mark a node and its children dirty (incremental updates).\"\"\"\n",
    "        if not node.is_dirty:\n",
    "            node.is_dirty = True\n",
    "            for child in node.children:\n",
    "                self.mark_dirty(child)\n",
    "\n",
    "    def execute_node(self, node: NodeInstance, level: int) -> NodeInstance:\n",
    "        \"\"\"Execute a single node with error handling and metrics.\"\"\"\n",
    "        start_time = time.time()\n",
    "        thread_id = threading.current_thread().name\n",
    "        success = True\n",
    "        error_msg = None\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Executing {node.name}\")\n",
    "\n",
    "            # Const nodes just have preset output1\n",
    "            if node.definition.type_name != \"CONST\":\n",
    "                resolved_inputs = node.resolve_inputs()\n",
    "\n",
    "                # Validate inputs\n",
    "                if not node.definition.validate_inputs(resolved_inputs):\n",
    "                    raise ValueError(f\"Invalid inputs for {node.name}\")\n",
    "\n",
    "                outputs = node.definition.compute(resolved_inputs)\n",
    "\n",
    "                with node.lock:\n",
    "                    node.outputs = outputs\n",
    "\n",
    "            logger.info(f\"Completed {node.name}: {node.outputs}\")\n",
    "\n",
    "            with node.lock:\n",
    "                node.is_dirty = False\n",
    "                node.retry_count = 0\n",
    "                node.last_error = None\n",
    "\n",
    "            # Record metrics\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            node.metrics.record_execution(duration)\n",
    "\n",
    "            # Checkpoint if enabled\n",
    "            if self.enable_checkpointing and self.checkpoint_callback:\n",
    "                self.checkpoint_callback(node)\n",
    "\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            node.metrics.record_error()\n",
    "            success = False\n",
    "            error_msg = str(e)\n",
    "\n",
    "            with node.lock:\n",
    "                node.last_error = e\n",
    "                node.retry_count += 1\n",
    "\n",
    "            logger.error(f\"Error executing {node.name}: {e}\")\n",
    "\n",
    "            # Retry logic\n",
    "            if node.retry_count < node.max_retries:\n",
    "                logger.warning(\n",
    "                    f\"Retrying {node.name} (attempt {node.retry_count + 1}/{node.max_retries})\"\n",
    "                )\n",
    "                return self.execute_node(node, level)\n",
    "            else:\n",
    "                logger.error(f\"Max retries exceeded for {node.name}\")\n",
    "                raise\n",
    "\n",
    "        # Record execution trace\n",
    "        if self.enable_profiling:\n",
    "            trace = ExecutionTrace(\n",
    "                node_name=node.name,\n",
    "                node_type=node.definition.type_name,\n",
    "                start_time=start_time - self.execution_start_time,\n",
    "                end_time=end_time - self.execution_start_time,\n",
    "                duration=duration,\n",
    "                level=level,\n",
    "                thread_id=thread_id,\n",
    "                success=success,\n",
    "                error=error_msg,\n",
    "            )\n",
    "            with self.traces_lock:\n",
    "                self.execution_traces.append(trace)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def execute_level_parallel(self, level: List[NodeInstance], level_idx: int):\n",
    "        \"\"\"Execute all nodes in a level using either sequential or parallel execution.\"\"\"\n",
    "        dirty_nodes = [node for node in level if node.is_dirty]\n",
    "\n",
    "        if not dirty_nodes:\n",
    "            return\n",
    "\n",
    "        level_start = time.time()\n",
    "\n",
    "        if self.mode == ExecutionMode.SEQUENTIAL:\n",
    "            # Sequential execution\n",
    "            logger.info(f\"Executing level with {len(dirty_nodes)} node(s) sequentially\")\n",
    "            completed = 0\n",
    "            for node in dirty_nodes:\n",
    "                try:\n",
    "                    self.execute_node(node, level_idx)\n",
    "                    completed += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to execute {node.name}: {e}\")\n",
    "                    raise\n",
    "        else:\n",
    "            # Parallel execution with ThreadPoolExecutor\n",
    "            logger.info(f\"Executing level with {len(dirty_nodes)} node(s) in parallel\")\n",
    "            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                futures = {\n",
    "                    executor.submit(self.execute_node, node, level_idx): node\n",
    "                    for node in dirty_nodes\n",
    "                }\n",
    "\n",
    "                completed = 0\n",
    "                for future in as_completed(futures):\n",
    "                    node = futures[future]\n",
    "                    try:\n",
    "                        future.result()\n",
    "                        completed += 1\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to execute {node.name}: {e}\")\n",
    "                        raise\n",
    "\n",
    "        level_time = time.time() - level_start\n",
    "        self.level_execution_times.append(level_time)\n",
    "        logger.info(\n",
    "            f\"Level completed in {level_time:.3f}s ({completed}/{len(dirty_nodes)} nodes)\"\n",
    "        )\n",
    "\n",
    "    def get_execution_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive execution statistics.\"\"\"\n",
    "        node_stats = []\n",
    "        for node in self.nodes:\n",
    "            node_stats.append(\n",
    "                {\n",
    "                    \"name\": node.name,\n",
    "                    \"type\": node.definition.type_name,\n",
    "                    \"execution_count\": node.metrics.execution_count,\n",
    "                    \"avg_time_ms\": node.metrics.avg_execution_time * 1000,\n",
    "                    \"error_count\": node.metrics.error_count,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"total_execution_time\": self.total_execution_time,\n",
    "            \"level_count\": len(self.execution_order),\n",
    "            \"level_execution_times\": self.level_execution_times,\n",
    "            \"node_stats\": node_stats,\n",
    "            \"total_nodes\": len(self.nodes),\n",
    "            \"execution_traces\": self.execution_traces,\n",
    "        }\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run execution with comprehensive logging and metrics.\"\"\"\n",
    "        self.execution_start_time = time.time()\n",
    "        execution_start = self.execution_start_time\n",
    "\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(\"Starting execution engine\")\n",
    "        logger.info(f\"Mode: {self.mode.value}, Max workers: {self.max_workers}\")\n",
    "        logger.info(\"=\" * 60)\n",
    "\n",
    "        # Compute execution order\n",
    "        self.execution_order = self.topological_sort()\n",
    "\n",
    "        logger.info(f\"Execution plan ({len(self.execution_order)} levels):\")\n",
    "        for i, level in enumerate(self.execution_order):\n",
    "            node_names = [node.name for node in level]\n",
    "            logger.info(f\"  Level {i}: {node_names}\")\n",
    "\n",
    "        # Execute each level\n",
    "        for level_idx, level in enumerate(self.execution_order):\n",
    "            logger.info(f\"\\n{'='*60}\")\n",
    "            logger.info(f\"Executing Level {level_idx}\")\n",
    "            logger.info(f\"{'='*60}\")\n",
    "            self.execute_level_parallel(level, level_idx)\n",
    "\n",
    "        self.total_execution_time = time.time() - execution_start\n",
    "\n",
    "        logger.info(\"\\n\" + \"=\" * 60)\n",
    "        logger.info(f\"Execution completed in {self.total_execution_time:.3f}s\")\n",
    "        logger.info(\"=\" * 60)\n",
    "\n",
    "        return self.get_execution_stats()\n",
    "\n",
    "    def plot_execution_profile(self, output_file: str = \"execution_profile.png\"):\n",
    "        \"\"\"Generate execution profile visualization as a Gantt chart.\"\"\"\n",
    "        if not self.execution_traces:\n",
    "            logger.warning(\"No execution traces available for profiling\")\n",
    "            return\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14, max(8, len(self.execution_traces) * 0.4)))\n",
    "\n",
    "        # Define colors for different node types\n",
    "        type_colors = {\n",
    "            \"CONST\": \"#3498db\",  # Blue\n",
    "            \"ADD\": \"#2ecc71\",  # Green\n",
    "            \"MULTIPLY\": \"#e74c3c\",  # Red\n",
    "            \"BASE\": \"#95a5a6\",  # Gray\n",
    "        }\n",
    "\n",
    "        # Sort traces by start time for better visualization\n",
    "        sorted_traces = sorted(self.execution_traces, key=lambda t: t.start_time)\n",
    "\n",
    "        # Create y-axis positions\n",
    "        y_positions = {}\n",
    "        current_y = 0\n",
    "\n",
    "        for trace in sorted_traces:\n",
    "            if trace.node_name not in y_positions:\n",
    "                y_positions[trace.node_name] = current_y\n",
    "                current_y += 1\n",
    "\n",
    "        # Plot each execution trace as a horizontal bar\n",
    "        for trace in sorted_traces:\n",
    "            y_pos = y_positions[trace.node_name]\n",
    "            color = type_colors.get(trace.node_type, \"#95a5a6\")\n",
    "\n",
    "            # Add alpha for failed executions\n",
    "            alpha = 0.4 if not trace.success else 0.8\n",
    "\n",
    "            ax.barh(\n",
    "                y_pos,\n",
    "                trace.duration,\n",
    "                left=trace.start_time,\n",
    "                height=0.8,\n",
    "                color=color,\n",
    "                alpha=alpha,\n",
    "                edgecolor=\"black\",\n",
    "                linewidth=0.5,\n",
    "            )\n",
    "\n",
    "            # Add duration label on the bar\n",
    "            if trace.duration > 0.001:  # Only show label if bar is wide enough\n",
    "                ax.text(\n",
    "                    trace.start_time + trace.duration / 2,\n",
    "                    y_pos,\n",
    "                    f\"{trace.duration*1000:.1f}ms\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontsize=8,\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"white\" if trace.duration > 0.02 else \"black\",\n",
    "                )\n",
    "\n",
    "        # Customize the plot\n",
    "        ax.set_yticks(range(len(y_positions)))\n",
    "        ax.set_yticklabels([name for name in y_positions.keys()])\n",
    "        ax.set_xlabel(\"Time (seconds)\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_ylabel(\"Node Name\", fontsize=12, fontweight=\"bold\")\n",
    "        ax.set_title(\n",
    "            \"Execution Profile - Parallel Node Execution Timeline\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            pad=20,\n",
    "        )\n",
    "\n",
    "        # Add grid for better readability\n",
    "        ax.grid(True, axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        # Create legend\n",
    "        legend_elements = [\n",
    "            mpatches.Patch(color=color, label=node_type, alpha=0.8)\n",
    "            for node_type, color in type_colors.items()\n",
    "            if any(t.node_type == node_type for t in sorted_traces)\n",
    "        ]\n",
    "        ax.legend(\n",
    "            handles=legend_elements,\n",
    "            loc=\"lower right\",\n",
    "            title=\"Node Types\",\n",
    "            framealpha=0.5,\n",
    "        )\n",
    "\n",
    "        # Add execution summary text\n",
    "        total_time = max(t.end_time for t in sorted_traces)\n",
    "        summary_text = f\"Total Execution Time: {total_time:.3f}s\\n\"\n",
    "        summary_text += f\"Nodes Executed: {len(sorted_traces)}\\n\"\n",
    "        summary_text += (\n",
    "            f\"Parallelization: {self.mode.value} ({self.max_workers} workers)\"\n",
    "        )\n",
    "\n",
    "        ax.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            summary_text,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=9,\n",
    "            verticalalignment=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5),\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_file, dpi=150, bbox_inches=\"tight\")\n",
    "        logger.info(f\"Execution profile saved to {output_file}\")\n",
    "        plt.close()\n",
    "\n",
    "    def export_graph(self, filepath: str):\n",
    "        \"\"\"Export graph structure to JSON for visualization/debugging.\"\"\"\n",
    "        graph_data = {\"nodes\": [node.to_json() for node in self.nodes], \"edges\": []}\n",
    "\n",
    "        for node in self.nodes:\n",
    "            for child in node.children:\n",
    "                graph_data[\"edges\"].append({\"from\": node.node_id, \"to\": child.node_id})\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            json.dump(graph_data, f, indent=2)\n",
    "\n",
    "        logger.info(f\"Graph exported to {filepath}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Example Usage\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create a more complex graph to demonstrate parallelization\n",
    "    constA = NodeInstance(\"ConstA\", NodeRegistry.create_definition(\"CONST\"), \"const_a\")\n",
    "    constA.outputs[\"output1\"] = 10\n",
    "\n",
    "    constB = NodeInstance(\"ConstB\", NodeRegistry.create_definition(\"CONST\"), \"const_b\")\n",
    "    constB.outputs[\"output1\"] = 4\n",
    "\n",
    "    constC = NodeInstance(\"ConstC\", NodeRegistry.create_definition(\"CONST\"), \"const_c\")\n",
    "    constC.outputs[\"output1\"] = 3\n",
    "\n",
    "    constD = NodeInstance(\"ConstD\", NodeRegistry.create_definition(\"CONST\"), \"const_d\")\n",
    "    constD.outputs[\"output1\"] = 10\n",
    "\n",
    "    add1 = NodeInstance(\"Add1\", NodeRegistry.create_definition(\"ADD\"), \"add_1\")\n",
    "    add1.set_input(1, constA, 1)\n",
    "    add1.set_input(2, constB, 1)\n",
    "\n",
    "    multiply1 = NodeInstance(\n",
    "        \"Multiply1\", NodeRegistry.create_definition(\"MULTIPLY\"), \"mult_1\"\n",
    "    )\n",
    "    multiply1.set_input(1, constC, 1)\n",
    "    multiply1.set_input(2, constD, 1)\n",
    "\n",
    "    add2 = NodeInstance(\"Add2\", NodeRegistry.create_definition(\"ADD\"), \"add_2\")\n",
    "    add2.set_input(1, add1, 1)\n",
    "    add2.set_input(2, multiply1, 1)\n",
    "\n",
    "    nodes = [constA, constB, constC, constD, add1, multiply1, add2]\n",
    "\n",
    "    # Run execution engine with ThreadPoolExecutor (FIXED)\n",
    "    engine = ExecutionEngine(\n",
    "        nodes,\n",
    "        max_workers=4,\n",
    "        mode=ExecutionMode.THREAD,  # Changed from PROCESS to THREAD\n",
    "        # mode=ExecutionMode.SEQUENTIAL,  # Changed from PROCESS to THREAD\n",
    "        enable_checkpointing=False,\n",
    "        enable_profiling=True,\n",
    "    )\n",
    "\n",
    "    stats = engine.run()\n",
    "\n",
    "    # Print execution statistics\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXECUTION STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total time: {stats['total_execution_time']:.3f}s\")\n",
    "    print(f\"Levels: {stats['level_count']}\")\n",
    "    print(f\"\\nNode Statistics:\")\n",
    "    for node_stat in stats[\"node_stats\"]:\n",
    "        print(\n",
    "            f\"  {node_stat['name']}: {node_stat['execution_count']} exec, \"\n",
    "            f\"{node_stat['avg_time_ms']:.2f}ms avg\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Add1 result: {add1.outputs['output1']} (10 + 4)\")\n",
    "    print(f\"Multiply1 result: {multiply1.outputs['output1']} (3 * 10)\")\n",
    "    print(f\"Add2 result: {add2.outputs['output1']} (14 + 30)\")\n",
    "\n",
    "    # Export graph for debugging\n",
    "    engine.export_graph(\"execution_graph.json\")\n",
    "    print(\"\\nGraph exported to execution_graph.json\")\n",
    "\n",
    "    # Generate execution profile visualization\n",
    "    engine.plot_execution_profile(\"execution_profile.png\")\n",
    "    print(\"Execution profile chart saved to execution_profile.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
